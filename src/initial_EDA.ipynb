{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "test_data_path = '../data/archive/test'\n",
    "train_data_path = '../data/archive/train'\n",
    "\n",
    "# each forlder has 7 subfolders representing 7 classes of emotions: anger, disgust, fear, happy, neutral, sad, surprise\n",
    "\n",
    "#write folder structure\n",
    "# archive (test, train) -> (anger, disgust, fear, happy, neutral, sad, surprise) -> (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='emotion'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count number of images in each folder\n",
    "# Test data\n",
    "test_data = {}\n",
    "for folder in os.listdir(test_data_path):\n",
    "    test_data[folder] = len(os.listdir(os.path.join(test_data_path, folder)))\n",
    "    \n",
    "# Train data\n",
    "train_data = {}\n",
    "for folder in os.listdir(train_data_path):\n",
    "    train_data[folder] = len(os.listdir(os.path.join(train_data_path, folder)))\n",
    "\n",
    "# create  one dataframe for 7 emotion and number of images in each folder for test and train data\n",
    "df = pd.DataFrame(test_data.items(), columns=['emotion', 'test_count'])\n",
    "df['train_count'] = train_data.values()\n",
    "\n",
    "df.plot(x='emotion', y=['test_count', 'train_count'], kind='bar', figsize=(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in test data:  7178\n",
      "Total number of images in train data:  28709\n",
      "Total number of images in whole dataset:  35887\n"
     ]
    }
   ],
   "source": [
    "# total number of images in test and train data, and total in whole dataset\n",
    "\n",
    "test_total = df['test_count'].sum()\n",
    "train_total = df['train_count'].sum()\n",
    "total = test_total + train_total\n",
    "print('Total number of images in test data: ', test_total)\n",
    "print('Total number of images in train data: ', train_total)\n",
    "print('Total number of images in whole dataset: ', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image = cv2.imread(os.path.join(test_data_path, folder, os.listdir(os.path.join(test_data_path, folder))[0]), cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "# import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU...\n"
     ]
    }
   ],
   "source": [
    "# check if cuda is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print('CUDA is available! Training on GPU...')\n",
    "else:\n",
    "    print('CUDA is not available. Training on CPU...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    # to-tensor\n",
    "    transforms.ToTensor(),\n",
    "    # normalize\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root='../data/archive/train', transform=transforms.ToTensor())\n",
    "# train_data = datasets.ImageFolder(root='../data/archive/test', transform=transforms.ToTensor())\n",
    "test_data = datasets.ImageFolder(root='../data/archive/test', transform=transforms.ToTensor())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 48, 48])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Load data on GPU if available\n",
    "if train_on_gpu:\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "else:\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# check if data is loaded correctly\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet = models.resnet18(weights= models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 57.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4 -- Training loss: 1.2302    Training accuracy: 0.7876   Validation loss: 1.2302\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 58.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 -- Training loss: 1.3402    Training accuracy: 0.8227   Validation loss: 1.3402\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 61.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 -- Training loss: 1.4188    Training accuracy: 0.8748   Validation loss: 1.4188\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 60.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 -- Training loss: 1.3924    Training accuracy: 0.8863   Validation loss: 1.3924\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:07<00:00, 61.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 -- Training loss: 1.5557    Training accuracy: 0.8685   Validation loss: 1.5557\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    " \n",
    "            # print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            # train phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in tqdm(train_loader):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            # print('Training loss: {:.4f}'.format(epoch_loss))\n",
    "            epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "            # print('Training accuracy: {:.4f}'.format(epoch_acc))\n",
    "            \n",
    "            \n",
    "            # validation phase\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in test_loader:\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                \n",
    "                \n",
    "            epoch_loss = running_loss / len(test_loader.dataset)\n",
    "            # print('Validation loss: {:.4f}'.format(epoch_loss))\n",
    "            \n",
    "            \n",
    "            print(f'Epoch {epoch}/{num_epochs - 1} -- Training loss: {epoch_loss:.4f}    Training accuracy: {epoch_acc:.4f}   Validation loss: {epoch_loss:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(resnet, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
